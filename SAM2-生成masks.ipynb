{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "dbfd63cd2bb4d58c",
   "metadata": {},
   "source": [
    "# 使用SAM2对图像进行分割标注\n",
    "相比上一版,将SAM预训练模型更改为SAM2,SAM2相比较SAM1,将模型从SVM更改为Transformer,提高了泛化能力和微调效果.\n",
    "\n",
    "**参考文献:**\n",
    "- [SAM2 Paper](https://ai.meta.com/research/publications/sam-2-segment-anything-in-images-and-videos/)\n",
    "- [SAM2 - GitHub](https://github.com/facebookresearch/segment-anything-2)\n",
    "- [(Official)SAM2 Image Predictor Example notebook - GitHub](https://github.com/facebookresearch/segment-anything-2/blob/main/notebooks/image_predictor_example.ipynb)\n",
    "- [(Official)Automatic Mask Generator Example notebook - GitHub](https://github.com/facebookresearch/segment-anything-2/blob/main/notebooks/automatic_mask_generator_example.ipynb)\n",
    "\n",
    "## SVM2主要优势有:\n",
    "- 提升了预训练模型的微调效果.(Paper - p11, zero-shot-image tasks)\n",
    "- 效率提升(image fps, 6.2x faster)\n",
    "- 更精确的图像掩码分割(在zero-shot, 1/5 click的情况下),比起SAM1识别出小物体和精细结构的能力提升(paper-p20,提升主要针对200像素以下,会自动填充间隙).\n",
    "- 流式记忆,可以将一组图片视为同一个序列来处理,可能可以解决单张图片不能输入全部信息的情况.\n",
    "\n",
    "## 预计下一步:\n",
    "1. 参考其他开放数据集的图像和数据标注方式,设计一个自己标注数据的方法\n",
    "2. 设计根据模型预测masks找出多边形顶点的方法\n",
    "    - 可能使用opencv库或者别的小规模机器学习模型识别,因为masks中像素点可能不完全连续,需要测试后确定\n",
    "    - 尝试是否可以让模型把每个缺陷部分都拆分成单独的masks组,之后再找顶点坐标,提升并发效率\n",
    "    - 是否需要按面积/具体边数标记缺陷\n",
    "3. 使用其他开放数据集微调模型,之后与原来的预训练模型效果比较,估测较好结果可能需要的数据量\n",
    "4. \n",
    "\n",
    "## 预计使用的其他类型开放数据集\n",
    "部分来源(有一组表面缺陷识别的开放数据集和paper): [GitHub - Surface Defect Detection: Dataset & Papers](https://github.com/Charmve/Surface-Defect-Detection)\n",
    "1. 医学超声\n",
    "2. 钢材缺陷 [Kaggle - Severstal: Steel Defect Detection](https://www.kaggle.com/c/severstal-steel-defect-detection/data)\n",
    "\n",
    "## 参考建议\n",
    "### 数据\n",
    "1. 半监督学习方法：给定少量精标注数据以及较多的无标注数据，在精标注数据上训练模型，在无标注数据上预测标签，生成粗标注数据，之后结合精标注数据和粗标注数据，扩充训练样本量[参考](https://blog.csdn.net/qq_44015059/article/details/106448533)\n",
    "2. 数据增强方法（文本数据，但可以参考）：利用现有数据，扩充训练数据集，从不同视角，参考论文：[A Group-Theoretic Framework for Data Augmentation](https://arxiv.org/abs/1907.10905), [Better Synthetic Data by Retrieving and Transforming Existing Datasets](https://arxiv.org/pdf/2404.14361), [When does data augmentation help generalization in NLP?](https://arxiv.org/pdf/2004.15012)\n",
    "\n",
    "### 模型\n",
    "1. 层次分类/聚类模型：流水线方法，构建标签的体系，如新闻分类中，首先构建一级分类器区分大类：如政治、体育、娱乐、游戏；之后在子分类中训练二级分类器，如体育分类下，有球类运动、水上运动、田径运动；根据需求进行更多级模型的构建，如球类运动分为，篮球、足球等。层次方法可以使用无监督模型进行初步的聚类分析（KNN等）。\n",
    "2. 集成学习方法：boosting（迭代，专注区分错误样本）、bagging（多个模型投票，加权得到最终结论）、stacking（模型流水线，子模型模型输出特征拼接到原始特征，最终模型学习上述全部特征并给出最终结果，通过多级流水线特征方法构建分类器系统）[一文读懂集成学习](https://github.com/THUDataPI/TechnologyOverview/blob/master/%E4%B8%80%E6%96%87%E8%AF%BB%E6%87%82%E9%9B%86%E6%88%90%E5%AD%A6%E4%B9%A0/%E4%B8%80%E6%96%87%E8%AF%BB%E6%87%82%E9%9B%86%E6%88%90%E5%AD%A6%E4%B9%A0.md)。\n",
    "3. 对比学习（contrastive learning）：比较并学习拉大正负样本之间的差异，来提高区别能力[A Simple Framework for Contrastive Learning of Visual Representations](https://arxiv.org/pdf/2002.05709)。\n",
    "4. 元学习（meta learning）：学习一个元学习器，用来生成（训练/选择）模型[Fast Task-Aware Architecture Inference](https://arxiv.org/abs/1902.05781)。\n",
    " \n",
    "### 训练\n",
    "1. 使用[tensorboard](https://www.tensorflow.org/tensorboard)（pytorch也可用）或者[wandb.ai](https://wandb.ai/site/)进行深度学习参数和训练过程管理，便于对比不同参数下结果的提升情况。\n",
    "2. 使用[accelerate](https://github.com/huggingface/accelerate)库进行训练加速。\n",
    "3. 机器学习模型参数选择：[网格搜索](https://www.cnblogs.com/wj-1314/p/10422159.html), [随机搜索](https://www.jiqizhixin.com/graph/technologies/c8b3090d-c81e-4141-a4ac-a86e193b3071), [遗传算法](https://blog.csdn.net/carlyll/article/details/105900317), [贝叶斯优化](https://www.cnblogs.com/milliele/p/17782631.html)。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc5d209cfc7f4fe5",
   "metadata": {},
   "source": [
    "## 导入所需库及预训练模型部分"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "32f6fba70b8022a1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-11T01:51:55.716042Z",
     "start_time": "2024-09-11T01:51:52.311736Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "using device: cuda\n"
     ]
    }
   ],
   "source": [
    "from numbers import Number\n",
    "\n",
    "import torch\n",
    "from sam2.build_sam import build_sam2\n",
    "from sam2.sam2_image_predictor import SAM2ImagePredictor\n",
    "from torch.utils.data import DataLoader\n",
    "import numpy as np\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "\n",
    "# 选择运行设备\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")\n",
    "elif torch.backends.mps.is_available():\n",
    "    device = torch.device(\"mps\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "print(f\"using device: {device}\")\n",
    "\n",
    "checkpoint = \"./checkpoints/sam2_hiera_large.pt\"\n",
    "model_cfg = \"sam2_hiera_l.yaml\"\n",
    "predictor = SAM2ImagePredictor(build_sam2(model_cfg, checkpoint))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74281acfc80e0221",
   "metadata": {},
   "source": [
    "## 定义过程中的输出/标注函数部分"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c4f3fe66e39334e1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-11T03:54:52.503159Z",
     "start_time": "2024-09-11T03:54:52.465632Z"
    }
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'Callable' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 73\u001b[0m\n\u001b[1;32m     68\u001b[0m     boundary_list \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m     70\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m boundary_list\n\u001b[0;32m---> 73\u001b[0m \u001b[38;5;28;43;01mclass\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;21;43;01mChipDefectDataSheetLoader\u001b[39;49;00m\u001b[43m(\u001b[49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mutils\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdata\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mDataset\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[1;32m     74\u001b[0m \u001b[38;5;250;43m    \u001b[39;49m\u001b[38;5;124;43;03m\"\"\"\u001b[39;49;00m\n\u001b[1;32m     75\u001b[0m \u001b[38;5;124;43;03m    数据加载器类\u001b[39;49;00m\n\u001b[1;32m     76\u001b[0m \u001b[38;5;124;43;03m    \"\"\"\u001b[39;49;00m\n\u001b[1;32m     78\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mdef\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;21;43m__init__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mimage_paths\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m[\u001b[49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmask_paths\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m[\u001b[49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     79\u001b[0m \u001b[43m                 \u001b[49m\u001b[43mtransform\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mCallable\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m>\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m:\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# transform是转换函数\u001b[39;49;00m\n",
      "Cell \u001b[0;32mIn[3], line 79\u001b[0m, in \u001b[0;36mChipDefectDataSheetLoader\u001b[0;34m()\u001b[0m\n\u001b[1;32m     73\u001b[0m \u001b[38;5;28;01mclass\u001b[39;00m \u001b[38;5;21;01mChipDefectDataSheetLoader\u001b[39;00m(torch\u001b[38;5;241m.\u001b[39mutils\u001b[38;5;241m.\u001b[39mdata\u001b[38;5;241m.\u001b[39mDataset):\n\u001b[1;32m     74\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     75\u001b[0m \u001b[38;5;124;03m    数据加载器类\u001b[39;00m\n\u001b[1;32m     76\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m     78\u001b[0m     \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, image_paths: \u001b[38;5;28mlist\u001b[39m[\u001b[38;5;28mstr\u001b[39m], mask_paths: \u001b[38;5;28mlist\u001b[39m[\u001b[38;5;28mstr\u001b[39m],\n\u001b[0;32m---> 79\u001b[0m                  transform: \u001b[43mCallable\u001b[49m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:  \u001b[38;5;66;03m# transform是转换函数\u001b[39;00m\n\u001b[1;32m     80\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mimage_paths \u001b[38;5;241m=\u001b[39m image_paths\n\u001b[1;32m     81\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmask_paths \u001b[38;5;241m=\u001b[39m mask_paths\n",
      "\u001b[0;31mNameError\u001b[0m: name 'Callable' is not defined"
     ]
    }
   ],
   "source": [
    "np.random.seed(3)\n",
    "\n",
    "def show_mask(mask, ax, random_color=False, borders=True):\n",
    "    if random_color:\n",
    "        color = np.concatenate([np.random.random(3), np.array([0.6])], axis=0)\n",
    "    else:\n",
    "        color = np.array([30 / 255, 144 / 255, 255 / 255, 0.6])\n",
    "    h, w = mask.shape[-2:]\n",
    "    mask = mask.astype(np.uint8)\n",
    "    mask_image = mask.reshape(h, w, 1) * color.reshape(1, 1, -1)\n",
    "    if borders:\n",
    "        import cv2\n",
    "        contours, _ = cv2.findContours(mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_NONE)\n",
    "        # Try to smooth contours\n",
    "        contours = [cv2.approxPolyDP(contour, epsilon=0.01, closed=True) for contour in contours]\n",
    "        mask_image = cv2.drawContours(mask_image, contours, -1, (1, 1, 1, 0.5), thickness=2)\n",
    "    ax.imshow(mask_image)\n",
    "\n",
    "\n",
    "def show_points(coords, labels, ax, marker_size=375):\n",
    "    pos_points = coords[labels == 1]\n",
    "    neg_points = coords[labels == 0]\n",
    "    ax.scatter(pos_points[:, 0], pos_points[:, 1], color='green', marker='*', s=marker_size, edgecolor='white',\n",
    "               linewidth=1.25)\n",
    "    ax.scatter(neg_points[:, 0], neg_points[:, 1], color='red', marker='*', s=marker_size, edgecolor='white',\n",
    "               linewidth=1.25)\n",
    "\n",
    "\n",
    "def show_box(box, ax):\n",
    "    x0, y0 = box[0], box[1]\n",
    "    w, h = box[2] - box[0], box[3] - box[1]\n",
    "    ax.add_patch(plt.Rectangle((x0, y0), w, h, edgecolor='green', facecolor=(0, 0, 0, 0), lw=2))\n",
    "\n",
    "\n",
    "def show_masks(image, masks, scores, point_coords=None, box_coords=None, input_labels=None, borders=True):\n",
    "    for i, (mask, score) in enumerate(zip(masks, scores)):\n",
    "        plt.figure(figsize=(10, 10))\n",
    "        plt.imshow(image)\n",
    "        show_mask(mask, plt.gca(), borders=borders)\n",
    "        if point_coords is not None:\n",
    "            assert input_labels is not None\n",
    "            show_points(point_coords, input_labels, plt.gca())\n",
    "        if box_coords is not None:\n",
    "            # boxes\n",
    "            show_box(box_coords, plt.gca())\n",
    "        if len(scores) > 1:\n",
    "            plt.title(f\"Mask {i + 1}, Score: {score:.3f}\", fontsize=18)\n",
    "        plt.axis('off')\n",
    "        plt.show()\n",
    "\n",
    "\n",
    "def find_polygon_boundary(matrix: np.ndarray):\n",
    "    \"\"\"\n",
    "    从二维布尔矩阵(如图形masks)中找到多边形顶点\n",
    "    Args:\n",
    "        matrix (np.ndarray): 单个2D numpy数组,True代表包含于多边形中.\n",
    "    Returns:\n",
    "        以元组形式存储单个多边形顶点的坐标,将所有顶点以列表形式返回\n",
    "    \"\"\"\n",
    "    # 设定矩阵数据类型\n",
    "    matrix = np.asarray(matrix, dtype=bool)\n",
    "    # 创建空矩阵\n",
    "    boundary = np.zeros_like(matrix, dtype=bool)\n",
    "\n",
    "    pass\n",
    "\n",
    "    boundary_list = []\n",
    "\n",
    "    return boundary_list\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d464e835dfef80ea",
   "metadata": {},
   "source": [
    "## 训练部分"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b733ef211910da2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 定义数据加载类\n",
    "class ChipDefectDatasetLoader(torch.utils.data.Dataset):\n",
    "    \"\"\"\n",
    "    数据加载器类\n",
    "    \"\"\"\n",
    "    def __init__(self, image_paths: list[str], mask_paths: list[str]) -> None:  # transform是转换函数\n",
    "        self.image_paths = image_paths\n",
    "        self.mask_paths = mask_paths\n",
    "\n",
    "    def __len__(self) -> Number:\n",
    "        return len(self.image_paths)\n",
    "\n",
    "    def __getitem__(self, idx: int):\n",
    "        image = cv2.imread(self.image_paths[idx])\n",
    "        mask = cv2.imread(self.mask_paths[idx])\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "            mask = self.transform(mask)\n",
    "\n",
    "        return image, mask\n",
    "# 加载训练数据\n",
    "image_paths = [\"./dataset/images\"]\n",
    "mask_paths = [\"./dataset/masks\"]\n",
    "train_dataset = ChipDefectDatasetLoader(image_paths, mask_paths)\n",
    "train_loader = DataLoader(train_dataset, batch_size=8, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c8fed238d9369f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 定义优化器和损失函数\n",
    "optimizer = torch.optim.Adam(predictor.parameters(), lr=1e-4)\n",
    "criterion = torch.nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7dd1a6247b601f7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 开始训练\n",
    "for epoch in range(num_epochs):\n",
    "    predictor.train()\n",
    "    running_loss = 0.0\n",
    "    for images, masks in train_loader:\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # 模型前向传播\n",
    "        masks_pred = predictor(images)\n",
    "\n",
    "        # 计算损失\n",
    "        loss = criterion(masks_pred, masks)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "    print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {running_loss/len(train_loader)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "675e6196ebf6c201",
   "metadata": {},
   "source": [
    "## 测试模型部分"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24aaa9c8d203641f",
   "metadata": {},
   "outputs": [],
   "source": [
    "pass"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e04803d14e8bf845",
   "metadata": {},
   "source": [
    "## 保存新的checkpoint部分"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45fd6238e045f38e",
   "metadata": {},
   "outputs": [],
   "source": [
    "pass"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
